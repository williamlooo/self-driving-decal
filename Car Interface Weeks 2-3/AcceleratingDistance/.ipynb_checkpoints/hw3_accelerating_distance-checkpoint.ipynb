{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import controller\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAR_MODEL = \"simple\"\n",
    "ci = controller.Car_Interface(model = CAR_MODEL)\n",
    "\n",
    "ci.set_gear(ci.FORWARD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(191)\n",
    "#generate input output pair\n",
    "#np.random(0,1)\n",
    "#([final_speed, distance_travelled],output)\n",
    "\n",
    "\n",
    "\n",
    "#(vf^2) /2*d = a\n",
    "\n",
    "#acceleration = (inp[0]**2) / (2*inp[1])\n",
    "\n",
    "#output = ((5*(inp[0]**2)) / inp[1])\n",
    "\n",
    "'''\n",
    "We want to make a model that can tell you how much\n",
    "you should depress the accelerator in order to achieve\n",
    "a target speed after travelling a target distance.\n",
    "\n",
    "Your goal is to randomly generate an (input, output)\n",
    "pair that can be used for training or evaluating your\n",
    "model. The input would be in the form of the final speed\n",
    "achieved and the distance travelled and the output would\n",
    "be the amount the pedal was accelerated to get there.\n",
    "'''\n",
    "def accelerating_distance_gen(ci):\n",
    "    \n",
    "    #CODE HERE\n",
    "    final_speed = random.uniform(0,1)\n",
    "    distance_travelled = random.uniform(0,1)*100\n",
    "    expected_pedal = ((5*(final_speed**2)) / distance_travelled)\n",
    "    \n",
    "    inp = [final_speed, distance_travelled]\n",
    "    \n",
    "    amt = ((5*(inp[0]**2)) / inp[1])\n",
    "\n",
    "    return amt, inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A car applied 0.50% accelerator, and achieved a speed of 30.24% after travelling 92.06 distance units\n"
     ]
    }
   ],
   "source": [
    "amt, (final_speed, distance_travelled) = accelerating_distance_gen(ci)\n",
    "print(f\"A car applied {amt * 100:.2f}% accelerator, and achieved a speed of {final_speed * 100:.2f}% after travelling {distance_travelled:.2f} distance units\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function should return how much distance the car\n",
    "would travel if the accelerator was being pressed amt\n",
    "until it acheived final_velocity\n",
    "'''\n",
    "def actual_accelerating_distance(final_velocity, amt):\n",
    "    #OPTIONAL CODE HERE\n",
    "    d = ((5*(final_velocity**2)) / amt)\n",
    "    return d\n",
    "\n",
    "def approximate_amount(inp, tol = 1e-5, min_amt = 0, max_amt = 1):\n",
    "    mid_amt = (min_amt + max_amt) / 2\n",
    "    if (max_amt - min_amt < 2 * tol):\n",
    "        return mid_amt\n",
    "\n",
    "    v, accelerating_distance = inp\n",
    "    if (actual_accelerating_distance(v, mid_amt) < accelerating_distance):\n",
    "        return approximate_amount(inp, tol, min_amt, mid_amt)\n",
    "    else:\n",
    "        return approximate_amount(inp, tol, mid_amt, max_amt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Fully Connected Module used to predict\n",
    "necessary accelerator pedal depression given\n",
    "target velocity and target distance from standstill.\n",
    "'''\n",
    "\"\"\"\n",
    "class fcn(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #CODE HERE\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "       #CODE HERE\n",
    "    \n",
    "\"\"\"    \n",
    "\n",
    "# Fully Connected Network Class (a custom subclass of torch's nn module)\n",
    "class fcn(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Number of hidden units in first hidden layer\n",
    "        self.H_1 = 30\n",
    "        # Number of hidden units in second hidden layer\n",
    "        self.H_2 = 20\n",
    "        \n",
    "        '''\n",
    "        Weights generally [input dim, output dim] so when we multiply a vector\n",
    "        of size [input dim] by a matrix of size [input dim, output dim] we get\n",
    "        a vector of size [output dim].  The bias will have shape [output dim]\n",
    "        so we can add it to the result of the weight-vector multiplication.\n",
    "        '''\n",
    "        \n",
    "        #Weights and Biases for computing input -> first hidden layer\n",
    "        self.W_1 = nn.Parameter(torch.randn([2, self.H_1]))\n",
    "        self.B_1 = nn.Parameter(torch.randn([self.H_1]))\n",
    "\n",
    "        #Weights and Biases for computing first -> second hidden layer\n",
    "        self.W_2 = nn.Parameter(torch.randn([self.H_1, self.H_2]))\n",
    "        self.B_2 = nn.Parameter(torch.randn([self.H_2]))\n",
    "        \n",
    "        #Weights and Biases for computing second hidden layer -> output\n",
    "        self.W_3 = nn.Parameter(torch.randn([self.H_2, 1]))\n",
    "        self.B_3 = nn.Parameter(torch.randn([1]))\n",
    "\n",
    "    # Forward propogation\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # x will be a vector of length 2 containing the initial velocity and desired stopping distance\n",
    "        x = torch.tensor(x, dtype = torch.float32)\n",
    "\n",
    "        # first hidden layer computation with tanh activation\n",
    "        h_1 = torch.tanh(torch.matmul(x, self.W_1) + self.B_1)\n",
    "    \n",
    "        # second hidden layer computation with tanh activation\n",
    "        h_2 = torch.tanh(torch.matmul(h_1, self.W_2) + self.B_2)\n",
    "        \n",
    "        #output computation with no activation.  We technically get a vector of length 1 so we squeeze to get value.\n",
    "        out = torch.squeeze(torch.matmul(h_2, self.W_3) + self.B_3)\n",
    "\n",
    "        '''\n",
    "        Our output is a scaled sigmoid (output range (0, 1.15)).  This helps model learn faster since all \n",
    "        desired outputs are in the range (0.15, 1).\n",
    "        '''\n",
    "        return 1.15 * torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 27.5630\n",
      "EPOCH 2 0.0116\n",
      "EPOCH 3 0.0224\n",
      "EPOCH 4 0.0404\n",
      "EPOCH 5 0.0206\n",
      "EPOCH 6 0.9596\n",
      "EPOCH 7 0.1870\n",
      "EPOCH 8 0.2663\n",
      "EPOCH 9 0.0200\n",
      "EPOCH 10 22.0855\n",
      "EPOCH 11 0.1992\n",
      "EPOCH 12 0.0216\n",
      "EPOCH 13 0.4755\n",
      "EPOCH 14 0.0092\n",
      "EPOCH 15 0.0181\n",
      "EPOCH 16 1.7288\n",
      "EPOCH 17 0.7656\n",
      "EPOCH 18 0.0128\n",
      "EPOCH 19 0.1681\n",
      "EPOCH 20 0.0089\n",
      "EPOCH 21 0.1512\n",
      "EPOCH 22 0.0097\n",
      "EPOCH 23 10.1512\n",
      "EPOCH 24 0.1330\n",
      "EPOCH 25 0.3296\n",
      "EPOCH 26 0.0187\n",
      "EPOCH 27 0.0567\n",
      "EPOCH 28 0.0152\n",
      "EPOCH 29 0.4336\n",
      "EPOCH 30 0.0311\n",
      "EPOCH 31 28.1813\n",
      "EPOCH 32 2.5751\n",
      "EPOCH 33 0.0059\n",
      "EPOCH 34 0.0024\n",
      "EPOCH 35 0.0080\n",
      "EPOCH 36 0.1848\n",
      "EPOCH 37 0.0121\n",
      "EPOCH 38 0.0030\n",
      "EPOCH 39 0.0358\n",
      "EPOCH 40 0.1935\n",
      "EPOCH 41 0.0104\n",
      "EPOCH 42 0.0010\n",
      "EPOCH 43 0.0059\n",
      "EPOCH 44 0.1502\n",
      "EPOCH 45 0.3950\n",
      "EPOCH 46 0.5382\n",
      "EPOCH 47 0.0911\n",
      "EPOCH 48 7.1089\n",
      "EPOCH 49 2.4961\n",
      "EPOCH 50 0.4750\n",
      "EPOCH 51 0.0877\n",
      "EPOCH 52 0.0056\n",
      "EPOCH 53 0.0263\n",
      "EPOCH 54 1.2429\n",
      "EPOCH 55 0.0094\n",
      "EPOCH 56 0.2062\n",
      "EPOCH 57 0.5150\n",
      "EPOCH 58 0.0203\n",
      "EPOCH 59 4.7090\n",
      "EPOCH 60 0.0024\n",
      "EPOCH 61 0.0094\n",
      "EPOCH 62 0.0130\n",
      "EPOCH 63 0.3458\n",
      "EPOCH 64 1.7842\n",
      "EPOCH 65 0.5111\n",
      "EPOCH 66 0.0111\n",
      "EPOCH 67 0.0233\n",
      "EPOCH 68 0.1107\n",
      "EPOCH 69 0.0461\n",
      "EPOCH 70 0.1209\n",
      "EPOCH 71 0.0009\n",
      "EPOCH 72 1.5618\n",
      "EPOCH 73 0.0018\n",
      "EPOCH 74 0.0051\n",
      "EPOCH 75 0.0343\n",
      "EPOCH 76 0.0206\n",
      "EPOCH 77 0.4363\n",
      "EPOCH 78 0.0093\n",
      "EPOCH 79 1.4746\n",
      "EPOCH 80 0.0026\n",
      "EPOCH 81 0.0018\n",
      "EPOCH 82 0.0018\n",
      "EPOCH 83 0.0126\n",
      "EPOCH 84 0.1304\n",
      "EPOCH 85 0.0013\n",
      "EPOCH 86 0.9259\n",
      "EPOCH 87 0.0702\n",
      "EPOCH 88 0.0111\n",
      "EPOCH 89 0.0004\n",
      "EPOCH 90 0.0613\n",
      "EPOCH 91 0.0754\n",
      "EPOCH 92 3.9278\n",
      "EPOCH 93 1.0406\n",
      "EPOCH 94 0.0265\n",
      "EPOCH 95 0.8150\n",
      "EPOCH 96 0.4441\n",
      "EPOCH 97 1.9286\n",
      "EPOCH 98 2.6382\n",
      "EPOCH 99 0.0154\n",
      "EPOCH 100 0.0009\n"
     ]
    }
   ],
   "source": [
    "#Initialize training parameters here\n",
    "\n",
    "USE_LAST = False\n",
    "EPOCHS = 100\n",
    "NUM_BATCHES = 10\n",
    "# Number of data points in a single batch\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "FN = \"weights_\" + CAR_MODEL\n",
    "\n",
    "model = fcn()\n",
    "if(USE_LAST):\n",
    "    model.load_state_dict(torch.load(open(FN + \".pt\", \"rb\")))\n",
    "\n",
    "#Initialize optimizer here\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    e_loss = 0\n",
    "    for b in range(NUM_BATCHES):\n",
    "        b_loss = 0\n",
    "        for i in range(BATCH_SIZE):\n",
    "            \n",
    "            #get example input output and increment batch loss based on model error\n",
    "            # Generate a data point\n",
    "            amt, inp = accelerating_distance_gen(ci)\n",
    "                \n",
    "            # Find the model's predicted acceleration amount\n",
    "            out = model(inp)\n",
    "                \n",
    "            # Compute MSE between model output and actual\n",
    "            amt_t = torch.tensor(amt)\n",
    "            b_loss += (out - amt_t) ** 2\n",
    "\n",
    "        b_loss /= BATCH_SIZE\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        b_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        b_loss = b_loss.detach().numpy()\n",
    "        print(f\"B {b} L {b_loss:.4f}\", end = \"\\r\")\n",
    "        e_loss += b_loss\n",
    "\n",
    "    e_loss /= NUM_BATCHES\n",
    "    print(f\"EPOCH {e + 1} {e_loss:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), open(FN + \".pt\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING 1/300\r",
      "TESTING 2/300\r",
      "TESTING 3/300\r",
      "TESTING 4/300\r",
      "TESTING 5/300\r",
      "TESTING 6/300\r",
      "TESTING 7/300\r",
      "TESTING 8/300\r",
      "TESTING 9/300\r",
      "TESTING 10/300\r",
      "TESTING 11/300\r",
      "TESTING 12/300\r",
      "TESTING 13/300\r",
      "TESTING 14/300\r",
      "TESTING 15/300\r",
      "TESTING 16/300\r",
      "TESTING 17/300\r",
      "TESTING 18/300\r",
      "TESTING 19/300\r",
      "TESTING 20/300\r",
      "TESTING 21/300\r",
      "TESTING 22/300\r",
      "TESTING 23/300\r",
      "TESTING 24/300\r",
      "TESTING 25/300\r",
      "TESTING 26/300\r",
      "TESTING 27/300\r",
      "TESTING 28/300\r",
      "TESTING 29/300\r",
      "TESTING 30/300\r",
      "TESTING 31/300\r",
      "TESTING 32/300\r",
      "TESTING 33/300\r",
      "TESTING 34/300\r",
      "TESTING 35/300\r",
      "TESTING 36/300\r",
      "TESTING 37/300\r",
      "TESTING 38/300\r",
      "TESTING 39/300\r",
      "TESTING 40/300\r",
      "TESTING 41/300\r",
      "TESTING 42/300\r",
      "TESTING 43/300\r",
      "TESTING 44/300\r",
      "TESTING 45/300\r",
      "TESTING 46/300\r",
      "TESTING 47/300\r",
      "TESTING 48/300\r",
      "TESTING 49/300\r",
      "TESTING 50/300\r",
      "TESTING 51/300\r",
      "TESTING 52/300\r",
      "TESTING 53/300\r",
      "TESTING 54/300\r",
      "TESTING 55/300\r",
      "TESTING 56/300\r",
      "TESTING 57/300\r",
      "TESTING 58/300\r",
      "TESTING 59/300\r",
      "TESTING 60/300\r",
      "TESTING 61/300\r",
      "TESTING 62/300\r",
      "TESTING 63/300\r",
      "TESTING 64/300\r",
      "TESTING 65/300\r",
      "TESTING 66/300\r",
      "TESTING 67/300\r",
      "TESTING 68/300\r",
      "TESTING 69/300\r",
      "TESTING 70/300\r",
      "TESTING 71/300\r",
      "TESTING 72/300\r",
      "TESTING 73/300\r",
      "TESTING 74/300\r",
      "TESTING 75/300\r",
      "TESTING 76/300\r",
      "TESTING 77/300\r",
      "TESTING 78/300\r",
      "TESTING 79/300\r",
      "TESTING 80/300\r",
      "TESTING 81/300\r",
      "TESTING 82/300\r",
      "TESTING 83/300\r",
      "TESTING 84/300\r",
      "TESTING 85/300\r",
      "TESTING 86/300\r",
      "TESTING 87/300\r",
      "TESTING 88/300\r",
      "TESTING 89/300\r",
      "TESTING 90/300\r",
      "TESTING 91/300\r",
      "TESTING 92/300\r",
      "TESTING 93/300\r",
      "TESTING 94/300\r",
      "TESTING 95/300\r",
      "TESTING 96/300\r",
      "TESTING 97/300\r",
      "TESTING 98/300\r",
      "TESTING 99/300\r",
      "TESTING 100/300\r",
      "TESTING 101/300\r",
      "TESTING 102/300\r",
      "TESTING 103/300\r",
      "TESTING 104/300\r",
      "TESTING 105/300\r",
      "TESTING 106/300\r",
      "TESTING 107/300\r",
      "TESTING 108/300\r",
      "TESTING 109/300\r",
      "TESTING 110/300\r",
      "TESTING 111/300\r",
      "TESTING 112/300\r",
      "TESTING 113/300\r",
      "TESTING 114/300\r",
      "TESTING 115/300\r",
      "TESTING 116/300\r",
      "TESTING 117/300\r",
      "TESTING 118/300\r",
      "TESTING 119/300\r",
      "TESTING 120/300\r",
      "TESTING 121/300\r",
      "TESTING 122/300\r",
      "TESTING 123/300\r",
      "TESTING 124/300\r",
      "TESTING 125/300\r",
      "TESTING 126/300\r",
      "TESTING 127/300\r",
      "TESTING 128/300\r",
      "TESTING 129/300\r",
      "TESTING 130/300\r",
      "TESTING 131/300\r",
      "TESTING 132/300\r",
      "TESTING 133/300\r",
      "TESTING 134/300\r",
      "TESTING 135/300\r",
      "TESTING 136/300\r",
      "TESTING 137/300\r",
      "TESTING 138/300\r",
      "TESTING 139/300\r",
      "TESTING 140/300\r",
      "TESTING 141/300\r",
      "TESTING 142/300\r",
      "TESTING 143/300\r",
      "TESTING 144/300\r",
      "TESTING 145/300\r",
      "TESTING 146/300\r",
      "TESTING 147/300\r",
      "TESTING 148/300\r",
      "TESTING 149/300\r",
      "TESTING 150/300\r",
      "TESTING 151/300\r",
      "TESTING 152/300\r",
      "TESTING 153/300\r",
      "TESTING 154/300\r",
      "TESTING 155/300\r",
      "TESTING 156/300\r",
      "TESTING 157/300\r",
      "TESTING 158/300\r",
      "TESTING 159/300\r",
      "TESTING 160/300\r",
      "TESTING 161/300\r",
      "TESTING 162/300\r",
      "TESTING 163/300\r",
      "TESTING 164/300\r",
      "TESTING 165/300\r",
      "TESTING 166/300\r",
      "TESTING 167/300\r",
      "TESTING 168/300\r",
      "TESTING 169/300\r",
      "TESTING 170/300\r",
      "TESTING 171/300\r",
      "TESTING 172/300\r",
      "TESTING 173/300\r",
      "TESTING 174/300\r",
      "TESTING 175/300\r",
      "TESTING 176/300\r",
      "TESTING 177/300\r",
      "TESTING 178/300\r",
      "TESTING 179/300\r",
      "TESTING 180/300\r",
      "TESTING 181/300\r",
      "TESTING 182/300\r",
      "TESTING 183/300\r",
      "TESTING 184/300\r",
      "TESTING 185/300\r",
      "TESTING 186/300\r",
      "TESTING 187/300\r",
      "TESTING 188/300\r",
      "TESTING 189/300\r",
      "TESTING 190/300\r",
      "TESTING 191/300\r",
      "TESTING 192/300\r",
      "TESTING 193/300\r",
      "TESTING 194/300\r",
      "TESTING 195/300\r",
      "TESTING 196/300\r",
      "TESTING 197/300\r",
      "TESTING 198/300\r",
      "TESTING 199/300\r",
      "TESTING 200/300\r",
      "TESTING 201/300\r",
      "TESTING 202/300\r",
      "TESTING 203/300\r",
      "TESTING 204/300\r",
      "TESTING 205/300\r",
      "TESTING 206/300\r",
      "TESTING 207/300\r",
      "TESTING 208/300\r",
      "TESTING 209/300\r",
      "TESTING 210/300\r",
      "TESTING 211/300\r",
      "TESTING 212/300\r",
      "TESTING 213/300\r",
      "TESTING 214/300\r",
      "TESTING 215/300\r",
      "TESTING 216/300\r",
      "TESTING 217/300\r",
      "TESTING 218/300\r",
      "TESTING 219/300\r",
      "TESTING 220/300\r",
      "TESTING 221/300\r",
      "TESTING 222/300\r",
      "TESTING 223/300\r",
      "TESTING 224/300\r",
      "TESTING 225/300\r",
      "TESTING 226/300\r",
      "TESTING 227/300\r",
      "TESTING 228/300\r",
      "TESTING 229/300\r",
      "TESTING 230/300\r",
      "TESTING 231/300\r",
      "TESTING 232/300\r",
      "TESTING 233/300\r",
      "TESTING 234/300\r",
      "TESTING 235/300\r",
      "TESTING 236/300\r",
      "TESTING 237/300\r",
      "TESTING 238/300\r",
      "TESTING 239/300\r",
      "TESTING 240/300\r",
      "TESTING 241/300\r",
      "TESTING 242/300\r",
      "TESTING 243/300\r",
      "TESTING 244/300\r",
      "TESTING 245/300\r",
      "TESTING 246/300\r",
      "TESTING 247/300\r",
      "TESTING 248/300\r",
      "TESTING 249/300\r",
      "TESTING 250/300\r",
      "TESTING 251/300\r",
      "TESTING 252/300\r",
      "TESTING 253/300\r",
      "TESTING 254/300\r",
      "TESTING 255/300\r",
      "TESTING 256/300\r",
      "TESTING 257/300\r",
      "TESTING 258/300\r",
      "TESTING 259/300\r",
      "TESTING 260/300\r",
      "TESTING 261/300\r",
      "TESTING 262/300\r",
      "TESTING 263/300\r",
      "TESTING 264/300\r",
      "TESTING 265/300\r",
      "TESTING 266/300\r",
      "TESTING 267/300\r",
      "TESTING 268/300\r",
      "TESTING 269/300\r",
      "TESTING 270/300\r",
      "TESTING 271/300\r",
      "TESTING 272/300\r",
      "TESTING 273/300\r",
      "TESTING 274/300\r",
      "TESTING 275/300\r",
      "TESTING 276/300\r",
      "TESTING 277/300\r",
      "TESTING 278/300\r",
      "TESTING 279/300\r",
      "TESTING 280/300\r",
      "TESTING 281/300\r",
      "TESTING 282/300\r",
      "TESTING 283/300\r",
      "TESTING 284/300\r",
      "TESTING 285/300\r",
      "TESTING 286/300\r",
      "TESTING 287/300\r",
      "TESTING 288/300\r",
      "TESTING 289/300\r",
      "TESTING 290/300\r",
      "TESTING 291/300\r",
      "TESTING 292/300\r",
      "TESTING 293/300\r",
      "TESTING 294/300\r",
      "TESTING 295/300\r",
      "TESTING 296/300\r",
      "TESTING 297/300\r",
      "TESTING 298/300\r",
      "TESTING 299/300\r",
      "TESTING 300/300\r",
      "WITHIN 0.1 294/300 times\n",
      "AVERAGE ERROR 0.01854503881596804\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "TEST = 300\n",
    "correct = 0\n",
    "tol = 0.1\n",
    "errors = []\n",
    "for i in range(TEST):\n",
    "    print(f\"TESTING {i + 1}/{TEST}\", end = \"\\r\")\n",
    "    amt, inp = accelerating_distance_gen(ci)\n",
    "\n",
    "    #run this to get FCN output\n",
    "    out = model(inp).detach().numpy()\n",
    "    \n",
    "    #run this to use analytical output\n",
    "    #out = approximate_amount(inp)\n",
    "\n",
    "    if (abs(out - amt) < tol):\n",
    "        correct += 1\n",
    "    errors.append(out - amt)\n",
    "print(f\"WITHIN {tol} {correct}/{TEST} times\")\n",
    "print(f\"AVERAGE ERROR {np.mean(np.abs(errors))}\")\n",
    "\n",
    "plt.title(\"Error Distribution\")\n",
    "plt.hist(errors, bins = 200, range = (-1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
